name: Deploy

on:
  push:
    branches: [ main ]
  workflow_dispatch: {}

concurrency:
  group: tf-misinfo-infra
  cancel-in-progress: true

jobs:
  apply:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    env:
      AWS_REGION: eu-north-1
      PROJECT_NAME: misinfo
      TFSTATE_BUCKET: misinfo-tfstate-eu-north-1-misinfo
      TFSTATE_KEY: infra/terraform.tfstate
      TF_LOCK_TABLE: misinfo-tf-locks

    steps:
      - uses: actions/checkout@v4

      - name: Zip Lambdas
        run: |
          set -euo pipefail
          mkdir -p dist
          (cd lambdas/ingest && zip -r ../../dist/ingest.zip .)
          (cd lambdas/api    && zip -r ../../dist/api.zip .)

      - name: Configure AWS via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      # --- Diagnose and align regions; create/clean lock table in BUCKET region ---
      - name: Diagnose AWS context
        run: |
          set -euo pipefail
          echo "== Caller identity =="
          aws sts get-caller-identity
          echo "== Runner AWS_REGION env =="
          echo "${AWS_REGION}"
          echo "== S3 bucket location =="
          aws s3api get-bucket-location --bucket "${TFSTATE_BUCKET}" || true
          echo "== DynamoDB tables in ${AWS_REGION} =="
          aws dynamodb list-tables --region "${AWS_REGION}" || true

      - name: Ensure lock table exists in S3 bucket's region & clear stale lock
        run: |
          set -euo pipefail

          # 1) Discover actual S3 bucket region (Terraform backend must use THIS)
          BUCKET_REGION=$(aws s3api get-bucket-location --bucket "${TFSTATE_BUCKET}" --query 'LocationConstraint' --output text)
          if [ "${BUCKET_REGION}" = "None" ] || [ "${BUCKET_REGION}" = "null" ]; then BUCKET_REGION="us-east-1"; fi
          echo "BUCKET_REGION=${BUCKET_REGION}" | tee -a $GITHUB_ENV

          # 2) Create lock table in same region if missing
          if ! aws dynamodb describe-table --table-name "${TF_LOCK_TABLE}" --region "${BUCKET_REGION}" >/dev/null 2>&1; then
            echo "Creating DynamoDB lock table ${TF_LOCK_TABLE} in ${BUCKET_REGION}"
            aws dynamodb create-table \
              --table-name "${TF_LOCK_TABLE}" \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --region "${BUCKET_REGION}"
          else
            echo "Lock table ${TF_LOCK_TABLE} already exists in ${BUCKET_REGION}"
          fi

          # 3) Wait for ACTIVE
          for i in {1..30}; do
            STATUS=$(aws dynamodb describe-table --table-name "${TF_LOCK_TABLE}" --region "${BUCKET_REGION}" --query 'Table.TableStatus' --output text 2>/dev/null || true)
            [ "$STATUS" = "ACTIVE" ] && break
            sleep 3
          done
          echo "Lock table status: ${STATUS:-unknown}"

          # 4) Delete any stale lock row by its partition key: bucket/key
          PK="${TFSTATE_BUCKET}/${TFSTATE_KEY}"
          echo "Deleting possible stale lock row: LockID=${PK} (region ${BUCKET_REGION})"
          aws dynamodb delete-item \
            --table-name "${TF_LOCK_TABLE}" \
            --key "{\"LockID\":{\"S\":\"${PK}\"}}" \
            --region "${BUCKET_REGION}" || true

          # 5) Show remaining rows (diagnostic)
          echo "== Lock table scan after delete (region ${BUCKET_REGION}) =="
          aws dynamodb scan \
            --table-name "${TF_LOCK_TABLE}" \
            --projection-expression "LockID,ID,Info" \
            --region "${BUCKET_REGION}" \
            --output json | jq -r '.Items'

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init (uses bucket's real region)
        working-directory: infra
        env:
          TF_VAR_project_name: ${{ env.PROJECT_NAME }}
          TF_VAR_region: ${{ env.AWS_REGION }}
          TF_VAR_github_owner: ${{ github.repository_owner }}
          TF_VAR_github_repo:  ${{ github.event.repository.name }}
          TF_VAR_sources_json: ${{ secrets.TF_VAR_sources_json }}
        run: |
          set -euo pipefail
          terraform init -upgrade -lock-timeout=5m \
            -backend-config="bucket=${TFSTATE_BUCKET}" \
            -backend-config="key=${TFSTATE_KEY}" \
            -backend-config="region=${BUCKET_REGION}" \
            -backend-config="dynamodb_table=${TF_LOCK_TABLE}" \
            -backend-config="encrypt=true"

      # Belt & suspenders: try the UUID you saw in logs (harmless if no lock)
      - name: Force unlock with known UUID (best-effort)
        working-directory: infra
        run: |
          set -euo pipefail
          terraform force-unlock -force 25987fdb-8820-15f5-6fa1-ca7403383f9f || true

      - name: Terraform Apply
        working-directory: infra
        env:
          TF_VAR_project_name: ${{ env.PROJECT_NAME }}
          TF_VAR_region: ${{ env.AWS_REGION }}
          TF_VAR_github_owner: ${{ github.repository_owner }}
          TF_VAR_github_repo:  ${{ github.event.repository.name }}
          TF_VAR_sources_json: ${{ secrets.TF_VAR_sources_json }}
        run: |
          set -euo pipefail
          terraform apply -lock-timeout=5m -auto-approve

      - name: Show outputs
        working-directory: infra
        run: terraform output

      - name: Clear lock on failure/cancel (best-effort)
        if: failure() || cancelled()
        working-directory: infra
        run: |
          set -euo pipefail
          terraform force-unlock -force 25987fdb-8820-15f5-6fa1-ca7403383f9f || true



